{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3-Semantic_Segmentation_Lab.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VwfKhFfHF27m"},"source":["# Semantic Segmentation with PyTorch"]},{"cell_type":"markdown","metadata":{"id":"qGeguvkAGNlw"},"source":["Mount google drive to colab."]},{"cell_type":"code","metadata":{"id":"RHc49hWDOJKw"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jly0ouf9eNOQ"},"source":["Import neccessary libraties and set parameters."]},{"cell_type":"code","metadata":{"id":"Qzie3tp6QThn"},"source":["import os\n","import time\n","import json\n","\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyGTWuMwngPV"},"source":["project_name = \"RNE_2022_Segmentation_Colab\"\n","project_path = \"/content/drive/My Drive/\" + project_name\n","train_dataset_path = project_path + \"/SimulationDataset/train\"\n","test_dataset_path = project_path + \"/SimulationDataset/test\"\n","\n","model_type = \"encdec\" # encdec / fcn / unet / pspnet\n","\n","# Create folder to store training results.\n","if model_type == \"encdec\":\n","    results_path = project_path + \"/results_encdec\"\n","elif model_type == \"fcn\":\n","    results_path = project_path + \"/results_fcn\"\n","elif model_type == \"unet\":\n","    results_path = project_path + \"/results_unet\"\n","elif model_type == \"pspnet\":\n","    results_path = project_path + \"/results_pspnet\"\n","\n","if os.path.isdir(results_path) == False:\n","   os.mkdir(results_path)\n","\n","# Parameters\n","num_class = 3 \n","input_h, input_w = 256, 256\n","batch_size = 16\n","epochs = 10\n","lr = 1e-4\n","use_gpu = torch.cuda.is_available()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nphF6DjpeZVB"},"source":["## Simulation Dataset"]},{"cell_type":"code","metadata":{"id":"HEgjfY74izJR"},"source":["class SimDataset(Dataset):\n","    def __init__(self, path, n_class=num_class, flip_rate=0.5, train=True):\n","        self.img_folder_path = path + \"/img\"\n","        self.label_folder_path = path + \"/label\"\n","        self.file_list = os.listdir(self.img_folder_path)\n","        self.n_class = n_class\n","        self.flip_rate = flip_rate\n","        self.train = train\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img_folder_path + \"/\" + self.file_list[idx]\n","        label_path = self.label_folder_path + \"/\" + \"jetbot_\" + self.file_list[idx].split(\"_\")[1] + \"_layer.png\"\n","\n","        # open image data\n","        img = np.asarray(Image.open(img_path).resize((256, 256), Image.NEAREST))\n","        img = img.astype(float)/255.0\n","        label_img = np.asarray(Image.open(label_path).resize((256, 256), Image.NEAREST))\n","        label = np.zeros((img.shape[0], img.shape[1], self.n_class), dtype=float)\n","        label[label_img[:,:,0]==178,0] = 1\n","        label[label_img[:,:,0]==255,1] = 1\n","        label[label_img[:,:,0]==0,2] = 1\n","\n","        if np.random.sample() < self.flip_rate:\n","            img = np.fliplr(img)\n","            label = np.fliplr(label)\n","\n","        img = torch.from_numpy(img.copy()).float()\n","        img = img.permute(2,0,1)\n","        label = torch.from_numpy(label.copy()).float()\n","        label = label.permute(2,0,1)\n","        sample = {\"X\": img, \"Y\": label}\n","        return sample\n","\n","# Load dataset\n","train_data = SimDataset(path=train_dataset_path, flip_rate=0.5)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n","test_data = SimDataset(path=test_dataset_path, flip_rate=0.0)\n","test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKvpt9GTefaL"},"source":["## Network Model\n","### VGG16 Feature Extractor (pretrained)"]},{"cell_type":"code","metadata":{"id":"CUfJoO8e-rrB"},"source":["class Vgg16(nn.Module):\n","    def __init__(self, pretrained = True):\n","        super(Vgg16, self).__init__()\n","        self.vggnet = models.vgg16(pretrained)\n","        del(self.vggnet.classifier) # Remove fully connected layer to save memory.\n","        features = list(self.vggnet.features)\n","        self.layers = nn.ModuleList(features).eval() \n","        \n","    def forward(self, x):\n","        results = []\n","        for ii,model in enumerate(self.layers):\n","            x = model(x)\n","            if ii in [3,8,15,22,29]:\n","                results.append(x) #(64,256,256),(128,128,128),(256,64,64),(512,32,32),(512,16,16)\n","        return results\n","\n","vgg_model = Vgg16()\n","vgg_model = vgg_model.cuda()\n","print(vgg_model.layers)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10fl6vwtE2Dz"},"source":["### Encoder-Decoder"]},{"cell_type":"code","metadata":{"id":"CVmJVvvj1W9H"},"source":["class DeConv2d(nn.Module):\n","    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, dilation):\n","        super().__init__()\n","        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n","        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\n","    \n","    def forward(self, x):\n","        output = self.up(x)\n","        output = self.conv(output)\n","        return output\n","\n","class EncoderDecoder(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn1 = nn.BatchNorm2d(512)\n","        \n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn2 = nn.BatchNorm2d(256)\n","        \n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\n","        self.bn4 = nn.BatchNorm2d(64)\n","        \n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        pre_output = self.pretrained_net(x)\n","        output = self.bn1(self.relu(self.deconv1(pre_output[4]))) #(512,32,32)\n","        output = self.bn2(self.relu(self.deconv2(output))) #(256,64,64)\n","        output = self.bn3(self.relu(self.deconv3(output))) #(128,128,128)\n","        output = self.bn4(self.relu(self.deconv4(output))) #(64,256,256)\n","        output = self.classifier(output)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-J1MWQfewD9"},"source":["### Fully Convolution Network (FCN)\n"]},{"cell_type":"code","metadata":{"id":"MjZ4-8X1EzFv"},"source":["class FCN(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        #####################################\n","        #TODO\n","        #####################################\n","\n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        #####################################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L5xIH1GffFXP"},"source":["### U-Net"]},{"cell_type":"code","metadata":{"id":"ZbAKDtkwJQH7"},"source":["class UNet(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        #####################################\n","        #TODO\n","        #####################################\n","    \n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        #####################################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwISqBr0yMTQ"},"source":["### PSPNet"]},{"cell_type":"code","metadata":{"id":"ttK5Y9AuyJ7y"},"source":["class PSPNet(nn.Module):\n","    def __init__(self, pretrained_net, n_class):\n","        super().__init__()\n","        self.n_class = n_class\n","        self.pretrained_net = pretrained_net\n","        #####################################\n","        #TODO\n","        #####################################\n","\n","    def forward(self, x):\n","        #####################################\n","        #TODO\n","        #####################################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjcje1cPfIYs"},"source":["Construct models."]},{"cell_type":"code","metadata":{"id":"oj3Ng3mi1deU"},"source":["if model_type == \"encdec\":\n","    seg_model = EncoderDecoder(pretrained_net=vgg_model, n_class=num_class)\n","elif model_type == \"fcn\":\n","    seg_model = FCN(pretrained_net=vgg_model, n_class=num_class)\n","elif model_type == \"unet\":\n","    seg_model = UNet(pretrained_net=vgg_model, n_class=num_class)\n","elif model_type == \"pspnet\":\n","    seg_model = PSPNet(pretrained_net=vgg_model, n_class=num_class)\n","\n","seg_model = seg_model.cuda()\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(seg_model.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9beJVr7yfNKT"},"source":["## Training and Validation"]},{"cell_type":"code","metadata":{"id":"pQtApd8vLCa8"},"source":["def train(seg_model, train_loader, test_loader):\n","    # pixel accuracy and mIOU list \n","    pixel_acc_list = []\n","    mIOU_list = []\n","    for epoch in range(1, epochs+1):\n","        ts = time.time()\n","        for iter, batch in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            inputs, labels = batch[\"X\"], batch[\"Y\"]\n","            if use_gpu:\n","              inputs = inputs.cuda()\n","              labels = labels.cuda()\n","\n","            outputs = seg_model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if iter % 10 == 0:\n","                print(\"epoch:{:2}, iter:{:2}, loss: {:.4f}\".format(epoch, iter, loss.data.item()))\n","        \n","        print(\"Finish epoch:{:2}, time elapsed: {:.4f}\".format(epoch, time.time() - ts))\n","        \n","        print(\"Start evaluation ...\")\n","        acc, iou = eval(seg_model, test_loader)\n","        pixel_acc_list.append(acc)\n","        mIOU_list.append(iou)\n","\n","        print(\"Output test results ...\")\n","        file_name = results_path + \"/\" + str(epoch).zfill(3) + \".jpg\"\n","        for iter, batch in enumerate(test_loader):\n","          inputs, labels = batch[\"X\"], batch[\"Y\"]\n","          if use_gpu:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","          outputs = seg_model(inputs)\n","          save_result(file_name, inputs, labels, outputs)\n","          break\n","        \n","        print(\"Save model ...\")\n","        model_path = results_path + \"/\" + \"segnet.pt\"\n","        torch.save(seg_model.state_dict(), model_path)\n","        print(\"========================================\")\n","        \n","    highest_pixel_acc = max(pixel_acc_list)\n","    highest_mIOU = max(mIOU_list)\n","    \n","    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n","    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n","    \n","    # Extract evaluation record\n","    record_path = results_path + \"/record.json\"\n","    ret = json.dumps({\"acc\":pixel_acc_list, \"iou\":mIOU_list})\n","    with open(record_path, 'w') as fp:\n","        fp.write(ret)\n","    \n","    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch+1))\n","    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch+1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DtvW9ZqJnmLE"},"source":["def eval(seg_model, test_loader):\n","    seg_model.eval()\n","    total_ious = []\n","    pixel_accs = []\n","\n","    for iter, batch in enumerate(test_loader): ## batch is 1 in this case\n","        inputs = torch.FloatTensor(batch[\"X\"])\n","        if use_gpu:\n","          inputs = inputs.cuda()\n","\n","        output = seg_model(inputs)\n","        \n","        # only save the 1st image for comparison\n","        if iter == 0:\n","            # generate images\n","            input_np = batch[\"X\"][0].data.cpu().numpy().transpose(1,2,0)\n","            output_np = output[0].data.cpu().numpy().transpose(1,2,0)\n","            gt_np = batch[\"Y\"][0].data.cpu().numpy().transpose(1,2,0)\n","        output = output.data.cpu().numpy()\n","\n","        N, _, h, w = output.shape\n","        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)\n","        target = batch['Y'].data.cpu().numpy().transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)\n","\n","        for p, t in zip(pred, target):\n","            total_ious.append(iou(p, t))\n","            pixel_accs.append(pixel_acc(p, t))\n","\n","    # Calculate average IoU\n","    total_ious = np.array(total_ious).T  # n_class * val_len\n","    ious = np.nanmean(total_ious, axis=1)\n","    pixel_accs = np.array(pixel_accs).mean()\n","    print(\"pix_acc: {:.4f}, meanIoU: {:.4f}\".format(pixel_accs, np.nanmean(ious)))\n","    return pixel_accs, np.nanmean(ious)\n","\n","# Calculates class intersections over unions\n","def iou(pred, target):\n","    ious = []\n","    for cls in range(num_class):\n","        pred_inds = pred == cls\n","        target_inds = target == cls\n","        intersection = pred_inds[target_inds].sum()\n","        union = pred_inds.sum() + target_inds.sum() - intersection\n","        if union == 0:\n","            ious.append(float(\"nan\")) # if there is no ground truth, do not include in evaluation\n","        else:\n","            ious.append(float(intersection) / max(union, 1))\n","    return ious\n","\n","def pixel_acc(pred, target):\n","    correct = (pred == target).sum()\n","    total = (target == target).sum()\n","    return correct / total\n","\n","def save_result(file_name, input, label, output, n_samples=3):\n","    input_np = input[:n_samples].data.cpu().numpy().transpose(0,2,3,1)\n","    label_np = label[:n_samples].data.cpu().numpy().transpose(0,2,3,1)\n","    output_np = output[:n_samples].data.cpu().numpy().transpose(0,2,3,1)\n","    \n","    result_list = []\n","    for k in range(n_samples):\n","        tmp = np.zeros([256,256,3], dtype=np.float32)\n","        for i in range(256):\n","            for j in range(256):\n","                tmp[i,j,output_np[k][i,j].argmax()] = 1\n","        result = np.hstack((input_np[k], label_np[k], tmp))\n","        result_list.append(result)\n","\n","    # horizontally stack original image and its corresponding segmentation results\n","    vstack_image = np.vstack(result_list)\n","    new_im = Image.fromarray(np.uint8(vstack_image*255))\n","    new_im.save(file_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q80RO6M5JmE5"},"source":["# perform training \n","train(seg_model, train_loader, test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Used for evaluation\n","#load_path = results_path + \"/\" + \"segnet.pt\"\n","#seg_model.load_state_dict(torch.load(load_path))\n","#eval(seg_model, test_loader)"],"metadata":{"id":"HomkgRihVXsM"},"execution_count":null,"outputs":[]}]}